{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path_dataset):\n",
    "    \"\"\" Clean initial dataset \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(path_dataset, sep=',')\n",
    "    \n",
    "    # Split id to user and movie\n",
    "    user_movie_df = pd.DataFrame(df.Id.str.split('_',1).tolist(),columns = ['User','Movie'])\n",
    "\n",
    "    # Map each user-movie to their corresponding prediction\n",
    "    output = df.join(user_movie_df)\n",
    "    output = output.drop(columns=['Id'])\n",
    "\n",
    "    # Remove \"r\" before id of each user\n",
    "    output['User'] = output['User'].map(lambda x: x.lstrip('r').rstrip('')).astype(int)\n",
    "\n",
    "    # Remove \"c\" before id of each user\n",
    "    output['Movie'] = output['Movie'].map(lambda x: x.lstrip('c').rstrip('')).astype(int)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"data/data_train.csv\"\n",
    "path_test_dataset = \"data/sample_submission.csv\"\n",
    "\n",
    "train_df = load_dataset(path_dataset)\n",
    "test_df = load_dataset(path_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  User  Movie\n",
       "0           4    44      1\n",
       "1           3    61      1\n",
       "2           4    67      1\n",
       "3           3    72      1\n",
       "4           5    86      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  User  Movie\n",
       "0           3    37      1\n",
       "1           3    73      1\n",
       "2           3   156      1\n",
       "3           3   160      1\n",
       "4           3   248      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (10000, 1000)\n",
      "the shape of valid ratings. (# of row, # of col): (9990, 999)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1065253\n",
      "Total number of nonzero elements in test data:111620\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of baseline using the global mean: [[1.12152228]].\n"
     ]
    }
   ],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    # find the non zero ratings in the train\n",
    "    nonzero_train = train[train.nonzero()]\n",
    "\n",
    "    # calculate the global mean\n",
    "    global_mean_train = nonzero_train.mean()\n",
    "\n",
    "    # find the non zero ratings in the test\n",
    "    nonzero_test = test[test.nonzero()].todense()\n",
    "\n",
    "    # predict the ratings as global mean\n",
    "    mse = calculate_mse(nonzero_test, global_mean_train)\n",
    "    rmse = np.sqrt(1.0 * mse / nonzero_test.shape[1])\n",
    "    print(\"test RMSE of baseline using the global mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean(train, test):\n",
    "    \"\"\"Use the global mean.\"\"\"\n",
    "\n",
    "    output = test.copy()\n",
    "    \n",
    "    # calculate the global mean\n",
    "    global_mean_train = train.Prediction.mean()\n",
    "\n",
    "    output.Prediction = global_mean_train\n",
    "    \n",
    "    def round_pred(row):\n",
    "        return round(row.Prediction)\n",
    "    \n",
    "    output['Prediction'] = output.apply(round_pred, axis=1)\n",
    "    return output\n",
    "\n",
    "pred_global_mean = global_mean(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, folds):\n",
    "    \"\"\"\n",
    "        This function will return two array including n (number of folds) different array which contains datasets \n",
    "        with almost same size in order to be used in cross-validation\n",
    "        \n",
    "        X: input data\n",
    "        folds: number of folds for cross validation or partitioning of the data\n",
    "        \n",
    "        X_output: An array including n arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    X = X.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    index_split_start = 0\n",
    "    index_split_end = int(np.floor(1/folds * len(X)))\n",
    "    \n",
    "    X_output = []\n",
    "    \n",
    "    for i in range(folds):\n",
    "        if i == folds - 1:\n",
    "            index_split_end = len(X)\n",
    "    \n",
    "        X_subset = X[index_split_start:index_split_end]\n",
    "        X_output.append(X_subset)\n",
    "        index_split_start = index_split_end\n",
    "        index_split_end += len(X_subset) \n",
    "        \n",
    "    return X_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_df(data_gt, data_pred):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse = 0\n",
    "    for index, row in data_gt.iterrows():\n",
    "        mse += (data_gt.Prediction[index] - data_pred.Prediction[index]) ** 2\n",
    "    return np.sqrt(1.0 * mse / len(data_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validator(model, dataset, n_fold):\n",
    "    \n",
    "    X_s = split_data(dataset, n_fold)\n",
    "    errors = []\n",
    "    for i in range(n_fold):\n",
    "        X_test = X_s[i]\n",
    "        X_train = pd.DataFrame(columns = X_test.columns)\n",
    "        \n",
    "        for j in range(n_fold):\n",
    "            if i == j:\n",
    "                continue\n",
    "            X_train = X_train.append(X_s[j], ignore_index=True)\n",
    "            \n",
    "        pred = model(X_train, X_test)\n",
    "        err = compute_error_df(X_test, pred)\n",
    "        errors.append(err)\n",
    "    \n",
    "    return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cross_validator(global_mean, train_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1281201372871368"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the user mean: [[1.03317038]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "\n",
    "    for user_index in range(num_users):\n",
    "        # find the non-zero ratings for each user in the training dataset\n",
    "        train_ratings = train[:, user_index]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "        \n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            user_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each user in the test dataset\n",
    "        test_ratings = test[:, user_index]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, user_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the user mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the item mean: [[1.09633198]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    for item_index in range(num_items):\n",
    "        # find the non-zero ratings for each item in the training dataset\n",
    "        train_ratings = train[item_index, :]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "\n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            item_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each movie in the test dataset\n",
    "        test_ratings = test[item_index, :]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, item_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the item mean: {v}.\".format(v=rmse))\n",
    "    \n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "        \n",
    "    num_item, num_user = train.get_shape()\n",
    "\n",
    "    user_features = np.random.rand(num_features, num_user)\n",
    "    item_features = np.random.rand(num_features, num_item)\n",
    "\n",
    "    # start by item features.\n",
    "    item_nnz = train.getnnz(axis=1)\n",
    "    item_sum = train.sum(axis=1)\n",
    "\n",
    "    for ind in range(num_item):\n",
    "        item_features[0, ind] = item_sum[ind, 0] / item_nnz[ind]\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse = 0\n",
    "    for row, col in nz:\n",
    "        item_info = item_features[:, row]\n",
    "        user_info = user_features[:, col]\n",
    "        mse += (data[row, col] - user_info.T.dot(item_info)) ** 2\n",
    "    return np.sqrt(1.0 * mse / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.1188016390962718.\n",
      "iter: 1, RMSE on training set: 1.0557733846363557.\n",
      "iter: 2, RMSE on training set: 1.0352090447321285.\n",
      "iter: 3, RMSE on training set: 1.0305003556868906.\n",
      "iter: 4, RMSE on training set: 1.0289338540768067.\n",
      "iter: 5, RMSE on training set: 1.027541155288929.\n",
      "iter: 6, RMSE on training set: 1.0267280525334728.\n",
      "iter: 7, RMSE on training set: 1.0257331157481897.\n",
      "iter: 8, RMSE on training set: 1.024212863517716.\n",
      "iter: 9, RMSE on training set: 1.0250155714728297.\n",
      "iter: 10, RMSE on training set: 1.0250110976515387.\n",
      "iter: 11, RMSE on training set: 1.0247649821945568.\n",
      "iter: 12, RMSE on training set: 1.024444922433812.\n",
      "iter: 13, RMSE on training set: 1.0243942405531554.\n",
      "iter: 14, RMSE on training set: 1.0244300096163954.\n",
      "iter: 15, RMSE on training set: 1.0244421403898756.\n",
      "iter: 16, RMSE on training set: 1.0243492826217602.\n",
      "iter: 17, RMSE on training set: 1.0241854571274716.\n",
      "iter: 18, RMSE on training set: 1.0243454281607476.\n",
      "iter: 19, RMSE on training set: 1.0243365237565685.\n",
      "RMSE on test data: 1.034557674453581.\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "            # update W_d (item_features[:, d]) and Z_n (user_features[:, n])\n",
    "            item_info = item_features[:, d]\n",
    "            user_info = user_features[:, n]\n",
    "            err = train[d, n] - user_info.T.dot(item_info)\n",
    "    \n",
    "            # calculate the gradient and update\n",
    "            item_features[:, d] += gamma * (err * user_info - lambda_item * item_info)\n",
    "            user_features[:, n] += gamma * (err * item_info - lambda_user * user_info)\n",
    "\n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "\n",
    "    # evaluate the test error\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "\n",
    "matrix_factorization_SGD(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    num_user = nnz_items_per_user.shape[0]\n",
    "    num_feature = item_features.shape[0]\n",
    "    lambda_I = lambda_user * sp.eye(num_feature)\n",
    "    updated_user_features = np.zeros((num_feature, num_user))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        # extract the columns corresponding to the prediction for given item\n",
    "        M = item_features[:, items]\n",
    "        \n",
    "        # update column row of user features\n",
    "        V = M @ train[items, user]\n",
    "        A = M @ M.T + nnz_items_per_user[user] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_user_features[:, user] = np.copy(X.T)\n",
    "    return updated_user_features\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    num_item = nnz_users_per_item.shape[0]\n",
    "    num_feature = user_features.shape[0]\n",
    "    lambda_I = lambda_item * sp.eye(num_feature)\n",
    "    updated_item_features = np.zeros((num_feature, num_item))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        # extract the columns corresponding to the prediction for given user\n",
    "        M = user_features[:, users]\n",
    "        V = M @ train[item, users].T\n",
    "        A = M @ M.T + nnz_users_per_item[item] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_item_features[:, item] = np.copy(X.T)\n",
    "    return updated_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start the ALS algorithm...\n",
      "RMSE on training set: 2.0667903099946097.\n",
      "RMSE on training set: 1.273082342531621.\n",
      "RMSE on training set: 1.1443723965394588.\n",
      "RMSE on training set: 1.0933056134082648.\n",
      "RMSE on training set: 1.0677955454860306.\n",
      "RMSE on training set: 1.053327562896735.\n",
      "RMSE on training set: 1.0444354568715422.\n",
      "RMSE on training set: 1.0386656716080207.\n",
      "RMSE on training set: 1.0347770575802664.\n",
      "RMSE on training set: 1.0320842183596965.\n",
      "RMSE on training set: 1.030182425919621.\n",
      "RMSE on training set: 1.0288198573234755.\n",
      "RMSE on training set: 1.0278332461774837.\n",
      "RMSE on training set: 1.0271132567742438.\n",
      "RMSE on training set: 1.0265847878082368.\n",
      "RMSE on training set: 1.0261952239391887.\n",
      "RMSE on training set: 1.0259071360511793.\n",
      "RMSE on training set: 1.0256935840162404.\n",
      "RMSE on training set: 1.0255350029344754.\n",
      "RMSE on training set: 1.0254170871091244.\n",
      "RMSE on training set: 1.025329322370854.\n",
      "test RMSE after running ALS: 1.03484581037619.\n"
     ]
    }
   ],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"\\nstart the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "\n",
    "    # evaluate the test error\n",
    "    nnz_row, nnz_col = test.nonzero()\n",
    "    nnz_test = list(zip(nnz_row, nnz_col))\n",
    "    rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "    print(\"test RMSE after running ALS: {v}.\".format(v=rmse))\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(prediction, output_name = \"submission.csv\"):\n",
    "    \"\"\"\n",
    "        prediction (Dataframe)\n",
    "        \n",
    "    \"\"\"\n",
    "    output_folder = \"output/\"\n",
    "    output = prediction.copy()\n",
    "    \n",
    "    def get_id(row):\n",
    "        return \"r\" + str(int(row.User)) + \"_c\" + str(int(row.Movie))\n",
    "    \n",
    "    def round_pred(row):\n",
    "        return round(row.Prediction)\n",
    "    \n",
    "    output['Id'] = output.apply(get_id, axis=1)\n",
    "    output['Prediction'] = output.apply(round_pred, axis=1)\n",
    "    \n",
    "    output[['Id', 'Prediction']].to_csv(output_folder + output_name, index=False)\n",
    "    return output[['Id', 'Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = create_submission_file(pred_global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
